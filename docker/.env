# ------------------------------
# API服务和worker的环境变量
# ------------------------------

# ------------------------------
# 通用变量
# ------------------------------

# 控制台API的后端URL，
# 用于拼接授权回调地址。
# 如果为空，则使用同一域名。
# 示例：https://api.console.dify.ai
CONSOLE_API_URL=

# 控制台web的前端URL，
# 用于拼接一些前端地址和CORS配置。
# 如果为空，则使用同一域名。
# 示例：https://console.dify.ai
CONSOLE_WEB_URL=

# 服务API Url，
# 用于向前端显示服务API基本Url。
# 如果为空，则为同一域。
# 示例：https://api.dify.ai
SERVICE_API_URL=

# WebApp API后端Url，
# 用于声明前端API的后端URL。
# 如果为空，则为同一域。
# 示例：https://api.app.dify.ai
APP_API_URL=http://192.168.0.123:5101

# WebApp Url，
# 用于向前端显示WebAPP API基本Url。
# 如果为空，则为同一域。
# 示例：https://app.dify.ai
APP_WEB_URL=http://192.168.0.123:5100

# 文件预览或下载Url前缀。
# 用于向前端显示文件预览或下载Url，或作为多模态输入；
# Url已签名并有过期时间。
FILES_URL=

# ------------------------------
# 服务器配置
# ------------------------------

# 应用程序的日志级别。
# 支持的值有 `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`
LOG_LEVEL=INFO
# 日志文件路径
LOG_FILE=/app/logs/server.log
# 日志文件最大大小，单位是MB
LOG_FILE_MAX_SIZE=20
# 日志文件最大备份数量
LOG_FILE_BACKUP_COUNT=5
# 日志日期格式
LOG_DATEFORMAT=%Y-%m-%d %H:%M:%S
# 日志时区
LOG_TZ=UTC

# 调试模式，默认为false。
# 建议在本地开发时开启此配置，
# 以防止由monkey patch引起的一些问题。
DEBUG=false

# Flask调试模式，开启后可以在接口处输出跟踪信息，
# 方便调试。
FLASK_DEBUG=false

# 用于安全签名会话cookie和加密数据库敏感信息的密钥。
# 可以使用`openssl rand -base64 42`生成强密钥。
SECRET_KEY=sk-9f73s3ljTXVcMT3Blb3ljTqtsKiGHXVcMT3BlbkFJLK7U

# 管理员用户初始化的密码。
# 如果留空，创建初始管理员账户时不会提示输入密码。
# 密码长度不能超过30个字符。
INIT_PASSWORD=

# 部署环境。
# 支持的值有 `PRODUCTION`, `TESTING`。默认为`PRODUCTION`。
# 测试环境。前端页面上会有明显的颜色标签，
# 表明此环境是测试环境。
DEPLOY_ENV=PRODUCTION

# 是否启用版本检查策略。
# 如果设置为空，将调用https://updates.dify.ai进行版本检查。
CHECK_UPDATE_URL=https://updates.dify.ai

# 用于更改OpenAI基础地址，默认为https://api.openai.com/v1。
# 当在中国无法访问OpenAI时，可以替换为国内镜像地址，
# 或者当本地模型提供OpenAI兼容API时，可以替换。
OPENAI_API_BASE=https://api.openai.com/v1

# 如果启用，应用程序启动前将执行迁移，
# 迁移完成后应用程序才会启动。
MIGRATION_ENABLED=true

# 文件访问时间指定文件可被访问的时间间隔（秒）。
# 默认值为300秒。
FILES_ACCESS_TIMEOUT=300

# 访问令牌过期时间（分钟）
ACCESS_TOKEN_EXPIRE_MINUTES=60

# 刷新令牌过期时间（天）
REFRESH_TOKEN_EXPIRE_DAYS=30

# 应用程序的最大活动请求数，0表示无限制，应为非负整数。
APP_MAX_ACTIVE_REQUESTS=0
APP_MAX_EXECUTION_TIME=1200

# ------------------------------
# 容器启动相关配置
# 仅在通过docker镜像或docker-compose启动时有效。
# ------------------------------

# API服务绑定地址，默认：0.0.0.0，即所有地址均可访问。
DIFY_BIND_ADDRESS=0.0.0.0

# API服务绑定端口号，默认5001。
DIFY_PORT=5001

# API服务器工作进程数量，即worker数量。
# 公式：CPU核心数 x 2 + 1（同步），1（Gevent）
# 参考：https://docs.gunicorn.org/en/stable/design.html#how-many-workers
SERVER_WORKER_AMOUNT=1

# 默认为gevent。如果在Windows上使用，可以切换为sync或solo。
SERVER_WORKER_CLASS=gevent

# 默认worker连接数，默认为10。
SERVER_WORKER_CONNECTIONS=10

# 类似于SERVER_WORKER_CLASS。
# 如果在Windows上使用，可以切换为sync或solo。
CELERY_WORKER_CLASS=

# 请求处理超时时间。默认为200，
# 建议设置为360以支持更长的sse连接时间。
GUNICORN_TIMEOUT=360

# Celery worker数量。默认为1，可根据需要设置。
CELERY_WORKER_AMOUNT=

# 是否启用Celery worker自动扩展的标志。
#
# 当任务对CPU要求高时，自动扩展很有用，
# 可以根据工作负载动态分配和释放worker。
#
# 当启用自动扩展时，可以指定worker的最大和最小数量。
# 自动扩展算法将在指定范围内动态调整worker数量。
#
# 默认为false（即禁用自动扩展）。
#
# 示例：
# CELERY_AUTO_SCALE=true
CELERY_AUTO_SCALE=false

# Celery worker自动扩展时的最大数量。
# 可选，仅在启用自动扩展时使用。
# 默认未设置。
CELERY_MAX_WORKERS=

# Celery worker自动扩展时的最小数量。
# 可选，仅在启用自动扩展时使用。
# 默认未设置。
CELERY_MIN_WORKERS=

# API工具配置
API_TOOL_DEFAULT_CONNECT_TIMEOUT=10
API_TOOL_DEFAULT_READ_TIMEOUT=60


# ------------------------------
# 数据库配置
# 数据库使用PostgreSQL。请使用public模式。
# 与下面'db'服务中的配置一致。
# ------------------------------

# 数据库连接池大小。
# 默认为30个连接，可以适当增加。
SQLALCHEMY_POOL_SIZE=30
# 数据库连接池回收时间，默认为3600秒。
SQLALCHEMY_POOL_RECYCLE=3600
# 是否打印SQL，默认为false。
SQLALCHEMY_ECHO=false

# 数据库最大连接数
# 默认为100
#
# 参考：https://www.postgresql.org/docs/current/runtime-config-connection.html#GUC-MAX-CONNECTIONS
POSTGRES_MAX_CONNECTIONS=100

# 设置用于postgres共享缓冲区的共享内存量。
# 默认为128MB
# 推荐值：可用内存的25%
# 参考：https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-SHARED-BUFFERS
POSTGRES_SHARED_BUFFERS=128MB

# 设置每个数据库worker用于工作空间的内存量。
# 默认为4MB
#
# 参考：https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-WORK-MEM
POSTGRES_WORK_MEM=4MB

# 设置用于维护活动的保留内存量。
# 默认为64MB
#
# 参考：https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAINTENANCE-WORK-MEM
POSTGRES_MAINTENANCE-WORK_MEM=64MB

# 设置规划器对有效缓存大小的假设。
# 默认为4096MB
#
# 参考：https://www.postgresql.org/docs/current/runtime-config-query.html#GUC-EFFECTIVE-CACHE-SIZE
POSTGRES_EFFECTIVE_CACHE_SIZE=4096MB

# ------------------------------
# Redis配置
# 此Redis配置用于缓存和对话期间的pub/sub。
# ------------------------------

# 是否使用Redis Sentinel模式。
# 如果设置为true，应用程序将通过Sentinel自动发现并连接到主节点。
REDIS_USE_SENTINEL=false

# Redis Sentinel节点列表。如果启用Sentinel模式，请提供至少一个Sentinel IP和端口。
# 格式：`<sentinel1_ip>:<sentinel1_port>,<sentinel2_ip>:<sentinel2_port>,<sentinel3_ip>:<sentinel3_port>`
REDIS_SENTINELS=

# 是否使用Redis Cluster模式。
# 如果启用Cluster模式，请提供至少一个Cluster IP和端口。
# 格式：`<Cluster1_ip>:<Cluster1_port>,<Cluster2_ip>:<Cluster2_port>,<Cluster3_ip>:<Cluster3_port>`
REDIS_USE_CLUSTERS=false

# ------------------------------
# Celery配置
# ------------------------------

# 使用redis作为broker，redis db 1用于celery broker。
# 格式如下：`redis://<redis_username>:<redis_password>@<redis_host>:<redis_port>/<redis_database>`
# 示例：redis://:difyai123456@redis:6379/1
# 如果使用Redis Sentinel，格式如下：`sentinel://<sentinel_username>:<sentinel_password>@<sentinel_host>:<sentinel_port>/<redis_database>`
# 示例：sentinel://localhost:26379/1;sentinel://localhost:26380/1;sentinel://localhost:26381/1
CELERY_BROKER_URL=redis://:123456@192.168.0.250:6379/2

# 如果使用Redis Sentinel实现高可用性，请配置以下设置。
CELERY_USE_SENTINEL=false

# ------------------------------
# CORS配置
# 用于设置前端跨域访问策略。
# ------------------------------

# 指定Web API跨域请求允许的来源，
# 例如https://dify.app或*表示所有来源。
WEB_API_CORS_ALLOW_ORIGINS=*

# 指定控制台API跨域请求允许的来源，
# 例如https://cloud.dify.ai或*表示所有来源。
CONSOLE_CORS_ALLOW_ORIGINS=*

# ------------------------------
# 文件存储配置
# ------------------------------

# 用于存储用户文件的存储类型。
STORAGE_TYPE=opendal

# Apache OpenDAL配置
# OpenDAL的配置由以下格式组成：OPENDAL_<SCHEME_NAME>_<CONFIG_NAME>。
# 您可以在以下仓库中找到所有服务配置(CONFIG_NAME)：https://github.com/apache/opendal/tree/main/core/src/services。
# Dify将扫描以OPENDAL_<SCHEME_NAME>开头的配置并自动应用它们。
# OpenDAL存储的方案名称。
OPENDAL_SCHEME=fs

# 是否使用AWS管理的IAM角色来验证S3服务。
# 如果设置为false，则必须提供访问密钥和密钥。
S3_USE_AWS_MANAGED_IAM=false

# ------------------------------
# 向量数据库配置
# ------------------------------

# 要使用的向量存储类型。
# 支持的值有 `weaviate`, `qdrant`, `milvus`, `myscale`, `relyt`, `pgvector`, `pgvecto-rs`, `chroma`, `opensearch`, `tidb_vector`, `oracle`, `tencent`, `elasticsearch`, `elasticsearch-ja`, `analyticdb`, `couchbase`, `vikingdb`, `oceanbase`, `opengauss`, `tablestore`。
VECTOR_STORE=weaviate

# Weaviate端点URL。仅在VECTOR_STORE为`weaviate`时可用。
WEAVIATE_ENDPOINT=http://weaviate:8080

# Qdrant端点URL。仅在VECTOR_STORE为`qdrant`时可用。
QDRANT_URL=http://qdrant:6333

# Milvus配置。仅在VECTOR_STORE为`milvus`时可用。
# milvus uri。
MILVUS_URI=http://host.docker.internal:19530

# MyScale配置，仅在VECTOR_STORE为`myscale`时可用
# 对于多语言支持，请参考以下设置MYSCALE_FTS_PARAMS：
# https://myscale.com/docs/en/text-search/#understanding-fts-index-parameters
MYSCALE_HOST=myscale

# Couchbase配置，仅在VECTOR_STORE为`couchbase`时可用
# 连接字符串必须包含docker-compose文件中定义的hostname（本例中为couchbase-server）
COUCHBASE_CONNECTION_STRING=couchbase://couchbase-server

# pgvector配置，仅在VECTOR_STORE为`pgvector`时可用
PGVECTOR_HOST=pgvector

# pgvecto-rs配置，仅在VECTOR_STORE为`pgvecto-rs`时可用
PGVECTO_RS_HOST=pgvecto-rs

# analyticdb配置，仅在VECTOR_STORE为`analyticdb`时可用
ANALYTICDB_KEY_ID=your-ak

# TiDB向量配置，仅在VECTOR_STORE为`tidb`时可用
TIDB_VECTOR_HOST=tidb

# Chroma配置，仅在VECTOR_STORE为`chroma`时可用
CHROMA_HOST=127.0.0.1

# Oracle配置，仅在VECTOR_STORE为`oracle`时可用
ORACLE_USER=dify

# relyt配置，仅在VECTOR_STORE为`relyt`时可用
RELYT_HOST=db

# opensearch配置，仅在VECTOR_STORE为`opensearch`时可用
OPENSEARCH_HOST=opensearch

# tencent向量配置，仅在VECTOR_STORE为`tencent`时可用
TENCENT_VECTOR_DB_URL=http://127.0.0.1

# ElasticSearch配置，仅在VECTOR_STORE为`elasticsearch`时可用
ELASTICSEARCH_HOST=0.0.0.0

# baidu向量配置，仅在VECTOR_STORE为`baidu`时可用
BAIDU_VECTOR_DB_ENDPOINT=http://127.0.0.1:5287

# VikingDB配置，仅在VECTOR_STORE为`vikingdb`时可用
VIKINGDB_ACCESS_KEY=your-ak

# OceanBase向量配置，仅在VECTOR_STORE为`oceanbase`时可用
OCEANBASE_VECTOR_HOST=oceanbase

# opengauss配置，仅在VECTOR_STORE为`opengauss`时可用
OPENGAUSS_HOST=opengauss

# Upstash向量配置，仅在VECTOR_STORE为`upstash`时可用
UPSTASH_VECTOR_URL=https://xxx-vector.upstash.io

# TableStore向量配置
# (仅在VECTOR_STORE为tablestore时使用)
TABLESTORE_ENDPOINT=https://instance-name.cn-hangzhou.ots.aliyuncs.com

# ------------------------------
# 知识库配置
# ------------------------------

# 上传文件大小限制，默认15M。
UPLOAD_FILE_SIZE_LIMIT=15

# 一次可上传的最大文件数，默认5。
UPLOAD_FILE_BATCH_LIMIT=5

# ETL类型，支持：`dify`, `Unstructured`
# `dify` Dify专有的文件提取方案
# `Unstructured` Unstructured.io文件提取方案
ETL_TYPE=dify

# Unstructured API路径和API密钥，当ETL_TYPE为Unstructured时需要配置
# 或当使用Unstructured作为pptx文档提取节点时。
# 例如：http://unstructured:8000/general/v0/general
UNSTRUCTURED_API_URL=

# ------------------------------
# 模型配置
# ------------------------------

# 提示生成允许的最大token数。
# 此设置控制LLM在提示生成工具中生成提示时可使用的token上限。
# 默认：512 tokens。
PROMPT_GENERATION_MAX_TOKENS=512

# 代码生成允许的最大token数。
# 此设置控制LLM在代码生成工具中生成代码时可使用的token上限。
# 默认：1024 tokens。
CODE_GENERATION_MAX_TOKENS=1024

# ------------------------------
# 多模态配置
# ------------------------------

# 当多模态模型输入时发送的图像/视频/音频/文档格式，
# 默认为base64，可选url。
# url模式的调用延迟将低于base64模式。
# 通常建议使用兼容性更好的base64模式。
# 如果配置为url，需要将FILES_URL配置为外部可访问地址，以便多模态模型可以访问图像/视频/音频/文档。
MULTIMODAL_SEND_FORMAT=base64
# 上传图片文件大小限制，默认10M。
UPLOAD_IMAGE_FILE_SIZE_LIMIT=10
# 上传视频文件大小限制，默认100M。
UPLOAD_VIDEO_FILE_SIZE_LIMIT=100
# 上传音频文件大小限制，默认50M。
UPLOAD_AUDIO_FILE_SIZE_LIMIT=50

# ------------------------------
# Sentry配置
# 用于应用程序监控和错误日志跟踪。
# ------------------------------

# API服务Sentry DSN地址，默认为空，为空时，
# 所有监控信息不会上报到Sentry。
# 如果未设置，将禁用Sentry错误报告。
API_SENTRY_DSN=
# API服务Sentry事件上报比例，如果是0.01，表示1%。
API_SENTRY_TRACES_SAMPLE_RATE=1.0
# API服务Sentry性能分析上报比例，如果是0.01，表示1%。
API_SENTRY_PROFILES_SAMPLE_RATE=1.0

# Web服务Sentry DSN地址，默认为空，为空时，
# 所有监控信息不会上报到Sentry。
# 如果未设置，将禁用Sentry错误报告。
WEB_SENTRY_DSN=

# ------------------------------
# Notion集成配置
# 变量可以通过申请Notion集成获取：https://www.notion.so/my-integrations
# ------------------------------

# 配置为"public"或"internal"。
# 由于Notion的OAuth重定向URL仅支持HTTPS，
# 如果在本地部署，请使用Notion的内部集成。
NOTION_INTEGRATION_TYPE=public
# Notion OAuth客户端密钥（用于公共集成类型）
NOTION_CLIENT_SECRET=
# Notion OAuth客户端ID（用于公共集成类型）
NOTION_CLIENT_ID=
# Notion内部集成密钥。
# 如果NOTION_INTEGRATION_TYPE的值为"internal"，
# 您需要配置此变量。
NOTION_INTERNAL_SECRET=

# ------------------------------
# 邮件相关配置
# ------------------------------

# 邮件类型，支持：resend, smtp
MAIL_TYPE=resend

# 默认发件人邮箱地址，如果未指定
MAIL_DEFAULT_SEND_FROM=

# Resend邮件提供商的API-Key，当MAIL_TYPE为`resend`时使用。
RESEND_API_URL=https://api.resend.com
RESEND_API_KEY=your-resend-api-key

# SMTP服务器配置，当MAIL_TYPE为`smtp`时使用
SMTP_SERVER=
SMTP_PORT=465
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_USE_TLS=true
SMTP_OPPORTUNISTIC_TLS=false

# ------------------------------
# 其他配置
# ------------------------------

# 索引的分段token最大长度
INDEXING_MAX_SEGMENTATION_TOKENS_LENGTH=4000

# 成员邀请链接有效时间（小时），
# 默认：72。
INVITE_EXPIRY_HOURS=72

# 重置密码token有效时间（分钟），
RESET_PASSWORD_TOKEN_EXPIRY_MINUTES=5

# 沙箱服务端点。
CODE_EXECUTION_ENDPOINT=http://sandbox:8194
CODE_EXECUTION_API_KEY=dify-sandbox
CODE_MAX_NUMBER=9223372036854775807
CODE_MIN_NUMBER=-9223372036854775808
CODE_MAX_DEPTH=5
CODE_MAX_PRECISION=20
CODE_MAX_STRING_LENGTH=80000
CODE_MAX_STRING_ARRAY_LENGTH=30
CODE_MAX_OBJECT_ARRAY_LENGTH=30
CODE_MAX_NUMBER_ARRAY_LENGTH=1000
CODE_EXECUTION_CONNECT_TIMEOUT=10
CODE_EXECUTION_READ_TIMEOUT=60
CODE_EXECUTION_WRITE_TIMEOUT=10
TEMPLATE_TRANSFORM_MAX_LENGTH=80000

# 工作流运行时配置
WORKFLOW_MAX_EXECUTION_STEPS=500
WORKFLOW_MAX_EXECUTION_TIME=1200
WORKFLOW_CALL_MAX_DEPTH=5
MAX_VARIABLE_SIZE=204800
WORKFLOW_PARALLEL_DEPTH_LIMIT=3
WORKFLOW_FILE_UPLOAD_LIMIT=10

# HTTP request node in workflow configuration
HTTP_REQUEST_NODE_MAX_BINARY_SIZE=10485760
HTTP_REQUEST_NODE_MAX_TEXT_SIZE=1048576
HTTP_REQUEST_NODE_SSL_VERIFY=True

# SSRF Proxy server HTTP URL
SSRF_PROXY_HTTP_URL=http://ssrf_proxy:3128
# SSRF Proxy server HTTPS URL
SSRF_PROXY_HTTPS_URL=http://ssrf_proxy:3128

# Maximum loop count in the workflow
LOOP_NODE_MAX_COUNT=100

# The maximum number of tools that can be used in the agent.
MAX_TOOLS_NUM=10

# Maximum number of Parallelism branches in the workflow
MAX_PARALLEL_LIMIT=10

# The maximum number of iterations for agent setting
MAX_ITERATIONS_NUM=5

# ------------------------------
# web服务环境变量
# ------------------------------

# The timeout for the text generation in millisecond
TEXT_GENERATION_TIMEOUT_MS=60000

# ------------------------------
# db服务环境变量
# ------------------------------

# The password for the default postgres user.
POSTGRES_PASSWORD=${DB_PASSWORD}
# The name of the default postgres database.
POSTGRES_DB=${DB_DATABASE}
# postgres data directory
PGDATA=/var/lib/postgresql/data/pgdata

# ------------------------------
# sandbox服务环境变量
# ------------------------------

# 沙箱服务的API密钥
SANDBOX_API_KEY=dify-sandbox
# Gin框架运行的模式
SANDBOX_GIN_MODE=release
# worker的超时时间（秒）
SANDBOX_WORKER_TIMEOUT=15
# 为沙箱服务启用网络
SANDBOX_ENABLE_NETWORK=true
# 用于SSRF防护的HTTP代理URL
SANDBOX_HTTP_PROXY=http://ssrf_proxy:3128
# 用于SSRF防护的HTTPS代理URL
SANDBOX_HTTPS_PROXY=http://ssrf_proxy:3128
# 沙箱服务运行的端口
SANDBOX_PORT=8194

# ------------------------------
# weaviate服务环境变量
# (仅在VECTOR_STORE为weaviate时使用)
# ------------------------------
WEAVIATE_PERSISTENCE_DATA_PATH=/var/lib/weaviate
WEAVIATE_QUERY_DEFAULTS_LIMIT=25
WEAVIATE_AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
WEAVIATE_DEFAULT_VECTORIZER_MODULE=none
WEAVIATE_CLUSTER_HOSTNAME=node1
WEAVIATE_AUTHENTICATION_APIKEY_ENABLED=true
WEAVIATE_AUTHENTICATION_APIKEY_ALLOWED_KEYS=WVF5YThaHlkYwhGUSmCRgsX3tD5ngdN8pkih
WEAVIATE_AUTHENTICATION_APIKEY_USERS=hello@dify.ai
WEAVIATE_AUTHORIZATION_ADMINLIST_ENABLED=true
WEAVIATE_AUTHORIZATION_ADMINLIST_USERS=hello@dify.ai

# ------------------------------
# Chroma环境变量
# (仅在VECTOR_STORE为chroma时使用)
# ------------------------------

# Chroma服务器的认证凭据
CHROMA_SERVER_AUTHN_CREDENTIALS=difyai123456
# 认证提供者
CHROMA_SERVER_AUTHN_PROVIDER=chromadb.auth.token_authn.TokenAuthenticationServerProvider
# 持久化设置
CHROMA_IS_PERSISTENT=TRUE

# ------------------------------
# Environment Variables for Oracle Service
# (only used when VECTOR_STORE is Oracle)
# ------------------------------
ORACLE_PWD=Dify123456
ORACLE_CHARACTERSET=AL32UTF8

# ------------------------------
# Environment Variables for milvus Service
# (only used when VECTOR_STORE is milvus)
# ------------------------------
# ETCD自动压缩模式配置
ETCD_AUTO_COMPACTION_MODE=revision
# ETCD自动压缩保留的修订版本数
ETCD_AUTO_COMPACTION_RETENTION=1000
# ETCD后端配额(字节)
ETCD_QUOTA_BACKEND_BYTES=4294967296
# 触发快照前的变更次数
ETCD_SNAPSHOT_COUNT=50000
# MinIO访问密钥
MINIO_ACCESS_KEY=minioadmin
# MinIO密钥
MINIO_SECRET_KEY=minioadmin
# ETCD服务端点
ETCD_ENDPOINTS=etcd:2379
# MinIO服务地址
MINIO_ADDRESS=minio:9000
# 启用或禁用安全授权
MILVUS_AUTHORIZATION_ENABLED=true

# ------------------------------
# pgvector/pgvector-rs服务环境变量
# (仅在VECTOR_STORE为pgvector/pgvector-rs时使用)
# ------------------------------
PGVECTOR_PGUSER=postgres
# 默认postgres用户的密码
PGVECTOR_POSTGRES_PASSWORD=difyai123456
# 默认postgres数据库名称
PGVECTOR_POSTGRES_DB=dify
# postgres数据目录
PGVECTOR_PGDATA=/var/lib/postgresql/data/pgdata

# ------------------------------
# opensearch环境变量
# (仅在VECTOR_STORE为opensearch时使用)
# ------------------------------
OPENSEARCH_DISCOVERY_TYPE=single-node
OPENSEARCH_BOOTSTRAP_MEMORY_LOCK=true
OPENSEARCH_JAVA_OPTS_MIN=512m
OPENSEARCH_JAVA_OPTS_MAX=1024m
OPENSEARCH_INITIAL_ADMIN_PASSWORD=Qazwsxedc!@#123
OPENSEARCH_MEMLOCK_SOFT=-1
OPENSEARCH_MEMLOCK_HARD=-1
OPENSEARCH_NOFILE_SOFT=65536
OPENSEARCH_NOFILE_HARD=65536

# ------------------------------
# Nginx反向代理环境变量
# ------------------------------
NGINX_SERVER_NAME=_
NGINX_HTTPS_ENABLED=false
# HTTP端口
NGINX_PORT=80
# SSL设置仅在HTTPS_ENABLED为true时应用
NGINX_SSL_PORT=443
# 如果HTTPS_ENABLED为true，需要将自己的SSL证书/密钥添加到`./nginx/ssl`目录
# 并相应修改下面的环境变量
NGINX_SSL_CERT_FILENAME=dify.crt
NGINX_SSL_CERT_KEY_FILENAME=dify.key
NGINX_SSL_PROTOCOLS=TLSv1.1 TLSv1.2 TLSv1.3

# Nginx性能调优
NGINX_WORKER_PROCESSES=auto
NGINX_CLIENT_MAX_BODY_SIZE=15M
NGINX_KEEPALIVE_TIMEOUT=65

# 代理设置
NGINX_PROXY_READ_TIMEOUT=3600s
NGINX_PROXY_SEND_TIMEOUT=3600s

# 设置为true以接受/.well-known/acme-challenge/的请求
NGINX_ENABLE_CERTBOT_CHALLENGE=false

# ------------------------------
# Certbot配置
# ------------------------------

# 电子邮件地址(从Let's Encrypt获取证书需要)
CERTBOT_EMAIL=your_email@example.com

# 域名
CERTBOT_DOMAIN=your_domain.com

# certbot命令选项
# 例如: --force-renewal --dry-run --test-cert --debug
CERTBOT_OPTIONS=

# ------------------------------
# SSRF代理环境变量
# ------------------------------
SSRF_HTTP_PORT=3128
SSRF_COREDUMP_DIR=/var/spool/squid
SSRF_REVERSE_PROXY_PORT=8194
SSRF_SANDBOX_HOST=sandbox
SSRF_DEFAULT_TIME_OUT=5
SSRF_DEFAULT_CONNECT_TIME_OUT=5
SSRF_DEFAULT_READ_TIME_OUT=5
SSRF_DEFAULT_WRITE_TIME_OUT=5

# ------------------------------
# 用于指定启动时向量数据库类型的docker环境变量
# (根据向量数据库类型，将使用相应的docker compose profile)
# 如果想使用unstructured，请在末尾添加',unstructured'
# ------------------------------
COMPOSE_PROFILES=${VECTOR_STORE:-weaviate}

# ------------------------------
# Docker Compose服务暴露主机端口配置
# ------------------------------
EXPOSE_NGINX_PORT=80
EXPOSE_NGINX_SSL_PORT=443

# ----------------------------------------------------------------------------
# 模型提供者和工具位置配置
# 用于指定应用中可使用的模型提供者和工具
# ----------------------------------------------------------------------------

# 固定、包含和排除工具
# 使用逗号分隔的值，项目之间没有空格
# 示例: POSITION_TOOL_PINS=bing,google
POSITION_TOOL_PINS=
POSITION_TOOL_INCLUDES=
POSITION_TOOL_EXCLUDES=

# 固定、包含和排除模型提供者
# 使用逗号分隔的值，项目之间没有空格
# 示例: POSITION_PROVIDER_PINS=openai,openllm
POSITION_PROVIDER_PINS=
POSITION_PROVIDER_INCLUDES=
POSITION_PROVIDER_EXCLUDES=

# CSP https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP
CSP_WHITELIST=

# Enable or disable create tidb service job
CREATE_TIDB_SERVICE_JOB_ENABLED=false

# Maximum number of submitted thread count in a ThreadPool for parallel node execution
MAX_SUBMIT_COUNT=100

# The maximum number of top-k value for RAG.
TOP_K_MAX_VALUE=10

# ------------------------------
# 插件守护进程配置
# ------------------------------

DB_PLUGIN_DATABASE=dify_plugin
EXPOSE_PLUGIN_DAEMON_PORT=5002
PLUGIN_DAEMON_PORT=5002
PLUGIN_DAEMON_KEY=lYkiYYT6owG+71oLerGzA7GXCgOT++6ovaezWAjpCjf+Sjc3ZtU+qUEi
PLUGIN_DAEMON_URL=http://plugin_daemon:5002
PLUGIN_MAX_PACKAGE_SIZE=52428800
PLUGIN_PPROF_ENABLED=false

PLUGIN_DEBUGGING_HOST=0.0.0.0
PLUGIN_DEBUGGING_PORT=5003
EXPOSE_PLUGIN_DEBUGGING_HOST=localhost
EXPOSE_PLUGIN_DEBUGGING_PORT=5003

# If this key is changed, DIFY_INNER_API_KEY in plugin_daemon service must also be updated or agent node will fail.
PLUGIN_DIFY_INNER_API_KEY=QaHbTe77CtuXmsfyhR7+vRjI/+XbV1AaFy691iy+kGDv2Jvy0/eAh8Y1
PLUGIN_DIFY_INNER_API_URL=http://api:5001

ENDPOINT_URL_TEMPLATE=http://localhost/e/{hook_id}

MARKETPLACE_ENABLED=true
MARKETPLACE_API_URL=https://marketplace.dify.ai

FORCE_VERIFYING_SIGNATURE=true

PLUGIN_PYTHON_ENV_INIT_TIMEOUT=120
PLUGIN_MAX_EXECUTION_TIMEOUT=600
# PIP_MIRROR_URL=https://pypi.tuna.tsinghua.edu.cn/simple
PIP_MIRROR_URL=

# https://github.com/langgenius/dify-plugin-daemon/blob/main/.env.example
# Plugin storage type, local aws_s3 tencent_cos azure_blob
PLUGIN_STORAGE_TYPE=local
PLUGIN_STORAGE_LOCAL_ROOT=/app/storage
PLUGIN_WORKING_PATH=/app/storage/cwd
PLUGIN_INSTALLED_PATH=plugin
PLUGIN_PACKAGE_CACHE_PATH=plugin_packages
PLUGIN_MEDIA_CACHE_PATH=assets
# Plugin oss bucket
PLUGIN_STORAGE_OSS_BUCKET=
# Plugin oss s3 credentials
PLUGIN_S3_USE_AWS_MANAGED_IAM=false
PLUGIN_S3_ENDPOINT=
PLUGIN_S3_USE_PATH_STYLE=false
PLUGIN_AWS_ACCESS_KEY=
PLUGIN_AWS_SECRET_KEY=
PLUGIN_AWS_REGION=
# Plugin oss azure blob
PLUGIN_AZURE_BLOB_STORAGE_CONTAINER_NAME=
PLUGIN_AZURE_BLOB_STORAGE_CONNECTION_STRING=
# Plugin oss tencent cos
PLUGIN_TENCENT_COS_SECRET_KEY=
PLUGIN_TENCENT_COS_SECRET_ID=
PLUGIN_TENCENT_COS_REGION=
